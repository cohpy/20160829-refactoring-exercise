{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook refactors\n",
    "[tf-05.py](https://github.com/crista/exercises-in-programming-style/blob/master/05-pipeline/tf-05.py),\n",
    "starting with the version from\n",
    "[d521abd 2016-05-21 08:14:41 -0700](https://github.com/crista/exercises-in-programming-style/blob/d521abd5d7aac14af19aa7794aca9ee23c0f8cc5/05-pipeline/tf-05.py).\n",
    "It was refactored by the audience at the 2016-08-29 [COhPy](cohpy.org)\n",
    "[meeting](http://www.meetup.com/Central-Ohio-Python-Users-Group/events/228901519/).\n",
    "\n",
    "The refactoring starts with cell #5. Cells before that setup the diff_python script to aid refactoring and later review. It shows:\n",
    "- changes in the source code from the previously executed cell\n",
    "- whether or not the output is correct\n",
    "  - if the output is not correct, shows differences from correct output\n",
    "- execution time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The license in the following cell covers only this notebook\n",
    "and is in addition to the LICENSE file in the parent directory\n",
    "of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MIT License (MIT)\n",
    "\n",
    "Copyright (c) 2016 James Prior, Travis Risner, Sam, Joe Friedrich, Russ Herrold, and Eric Floehr\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of\n",
    "this software and associated documentation files (the \"Software\"), to deal in\n",
    "the Software without restriction, including without limitation the rights to\n",
    "use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of\n",
    "the Software, and to permit persons to whom the Software is furnished to do so,\n",
    "subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS\n",
    "FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR\n",
    "COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER\n",
    "IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
    "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "First we run the program, and save its output.\n",
    "\n",
    "The original code runs only in Python 2, but my virtual environment runs Python 3 by default, so Python 2 is used explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr  -  786\r\n",
      "elizabeth  -  635\r\n",
      "very  -  488\r\n",
      "darcy  -  418\r\n",
      "such  -  395\r\n",
      "mrs  -  343\r\n",
      "much  -  329\r\n",
      "more  -  327\r\n",
      "bennet  -  323\r\n",
      "bingley  -  306\r\n",
      "jane  -  295\r\n",
      "miss  -  283\r\n",
      "one  -  275\r\n",
      "know  -  239\r\n",
      "before  -  229\r\n",
      "herself  -  227\r\n",
      "though  -  226\r\n",
      "well  -  224\r\n",
      "never  -  220\r\n",
      "sister  -  218\r\n",
      "soon  -  216\r\n",
      "think  -  211\r\n",
      "now  -  209\r\n",
      "time  -  203\r\n",
      "good  -  201\r\n"
     ]
    }
   ],
   "source": [
    "!python2 tf-05.py ../pride-and-prejudice.txt | tee good_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating new cells interactively,\n",
    "one knows exactly what the changes are because they were just done.\n",
    "But when one looks at the cells later,\n",
    "how does one know what all the little changes were?\n",
    "It would be nice the see the differences\n",
    "between one cell and another as the refactoring progresses.\n",
    "So cell magic is used to show the difference\n",
    "between a cell and the previously executed cell.\n",
    "\n",
    "After that, any difference between what the output should be\n",
    "and what is actually is, is shown.\n",
    "\n",
    "One complication is that since my trickery\n",
    "executes cells outside Jupyter notebook,\n",
    "the cells do not have access to variables\n",
    "from Jupyter notebook and vice versa.\n",
    "\n",
    "One nice thing about running the cells outside Jupyter,\n",
    "is that we know each cell has all the stuff it needs\n",
    "and does not rely on some result from a previous cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Create the diff_python script\n",
    "that will be executed by %%script magic\n",
    "to show differences between cells,\n",
    "and differences in output from what it should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# As we refactor, it would be nice to see the difference between\n",
    "# one cell and the previously executed cell.\n",
    "# This script creates a shell script that\n",
    "# does that when executed with the %%script diff_python\n",
    "# at the beginning of a cell.\n",
    "#\n",
    "# To disable the diff command,\n",
    "# Put a : and space in front of it. I.e.,\n",
    "#     : diff old.py new.py\n",
    "#\n",
    "# meld yields a beautiful diff,\n",
    "# but pops up a window for each cell executed.\n",
    "\n",
    "program_name=\"${PATH%%:*}/diff_python\"\n",
    "\n",
    "cat >\"$program_name\" <<EOF\n",
    "#!/usr/bin/env bash\n",
    "cat >new.py\n",
    "chmod +x new.py\n",
    "if [ -a old.py ]; then\n",
    "    diff old.py new.py\n",
    "fi\n",
    "chmod +x new.py\n",
    "time ./new.py ../pride-and-prejudice.txt >new_output\n",
    "echo\n",
    "if cmp -s new_output good_output; then\n",
    "    echo GOOD: the output is good\n",
    "else\n",
    "    echo ERROR: new_output is different from good_output\n",
    "    # md5sum good_output new_output\n",
    "    diff good_output new_output\n",
    "fi\n",
    "mv new.py old.py\n",
    "EOF\n",
    "rm -f old.py\n",
    "chmod +x \"$program_name\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From now on,\n",
    "each cell will start with the %%script diff_python magic.\n",
    "The original code is repeated below with the addition\n",
    "of the %%script diff_python magic at the beginning,\n",
    "changing the #!/usr/bin/env python to #!/usr/bin/env python2,\n",
    "and a change to deliberately cause a bug for the cmp to catch.\n",
    "This also initializes the code differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR: new_output is different from good_output\n",
      "1,2d0\n",
      "< mr  -  786\n",
      "< elizabeth  -  635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.353s\n",
      "user\t0m0.340s\n",
      "sys\t0m0.008s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python2\n",
    "import sys, re, operator, string\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    word_freqs = {}\n",
    "    for w in word_list:\n",
    "        if w in word_freqs:\n",
    "            word_freqs[w] += 1\n",
    "        else:\n",
    "            word_freqs[w] = 1\n",
    "    return word_freqs\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print word_freqs[0][0], ' - ', word_freqs[0][1]\n",
    "        print_all(word_freqs[1:]);\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[2:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diff_python correctly detected the change in output,\n",
    "so we know that diff_python works. \n",
    "\n",
    "So next we undo that change so the output is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74c74\n",
      "< print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[2:25])\n",
      "---\n",
      "> print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.354s\n",
      "user\t0m0.324s\n",
      "sys\t0m0.028s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python2\n",
    "import sys, re, operator, string\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    word_freqs = {}\n",
    "    for w in word_list:\n",
    "        if w in word_freqs:\n",
    "            word_freqs[w] += 1\n",
    "        else:\n",
    "            word_freqs[w] = 1\n",
    "    return word_freqs\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print word_freqs[0][0], ' - ', word_freqs[0][1]\n",
    "        print_all(word_freqs[1:]);\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we start refactoring, one thing at a time.\n",
    "\n",
    "Python 2 is [scheduled to retire in 2020](https://pythonclock.org/),\n",
    "so let's port it to Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1c1\n",
      "< #!/usr/bin/env python2\n",
      "---\n",
      "> #!/usr/bin/env python3\n",
      "61c61\n",
      "<     return sorted(word_freq.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "---\n",
      ">     return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
      "68c68\n",
      "<         print word_freqs[0][0], ' - ', word_freqs[0][1]\n",
      "---\n",
      ">         print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.500s\n",
      "user\t0m0.468s\n",
      "sys\t0m0.024s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    word_freqs = {}\n",
    "    for w in word_list:\n",
    "        if w in word_freqs:\n",
    "            word_freqs[w] += 1\n",
    "        else:\n",
    "            word_freqs[w] = 1\n",
    "    return word_freqs\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
    "        print_all(word_freqs[1:]);\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the addition of the following line\n",
    "\n",
    "    from __future__ import print_function\n",
    "    \n",
    "the above code would work with either Python 2 or Python 3.\n",
    "That was not thought of at the meeting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Travis Risner came up with the next thing to improve.\n",
    "Use a\n",
    "[sortedcontainers](https://pypi.python.org/pypi/sortedcontainers).SortedDict\n",
    "to avoid the sorted function in sort().\n",
    "\n",
    "This was abandoned when it was realized that it was not \n",
    "in the standard library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2a3\n",
      "> from sortedcontainers import sortedDict # not standard library\n",
      "47c48\n",
      "<     word_freqs = {}\n",
      "---\n",
      ">     word_freqs = SortedDict()\n",
      "61c62,63\n",
      "<     return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
      "---\n",
      ">     # return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
      ">     return word_freq\n",
      "\n",
      "ERROR: new_output is different from good_output\n",
      "1,25d0\n",
      "< mr  -  786\n",
      "< elizabeth  -  635\n",
      "< very  -  488\n",
      "< darcy  -  418\n",
      "< such  -  395\n",
      "< mrs  -  343\n",
      "< much  -  329\n",
      "< more  -  327\n",
      "< bennet  -  323\n",
      "< bingley  -  306\n",
      "< jane  -  295\n",
      "< miss  -  283\n",
      "< one  -  275\n",
      "< know  -  239\n",
      "< before  -  229\n",
      "< herself  -  227\n",
      "< though  -  226\n",
      "< well  -  224\n",
      "< never  -  220\n",
      "< sister  -  218\n",
      "< soon  -  216\n",
      "< think  -  211\n",
      "< now  -  209\n",
      "< time  -  203\n",
      "< good  -  201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"./new.py\", line 3, in <module>\n",
      "    from sortedcontainers import sortedDict # not standard library\n",
      "ImportError: No module named 'sortedcontainers'\n",
      "\n",
      "real\t0m0.046s\n",
      "user\t0m0.036s\n",
      "sys\t0m0.008s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from sortedcontainers import sortedDict # not standard library\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    word_freqs = SortedDict()\n",
    "    for w in word_list:\n",
    "        if w in word_freqs:\n",
    "            word_freqs[w] += 1\n",
    "        else:\n",
    "            word_freqs[w] = 1\n",
    "    return word_freqs\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    # return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return word_freq\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
    "        print_all(word_freqs[1:]);\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sam improved the counting by using a \n",
    "[defaultdict](https://docs.python.org/3/library/collections.html#collections.defaultdict).\n",
    "It definitely cleaned up the counting code,\n",
    "eliminating the if/else structure.\n",
    "\n",
    "There was confusion about how to use a defaultdict.\n",
    "The first argument is a callable,\n",
    "which returns the default value.\n",
    "int() called with no arguments returns 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3c3\n",
      "< from sortedcontainers import sortedDict # not standard library\n",
      "---\n",
      "> from collections import defaultdict\n",
      "48c48\n",
      "<     word_freqs = SortedDict()\n",
      "---\n",
      ">     word_freqs = defaultdict(int)\n",
      "50,53c50\n",
      "<         if w in word_freqs:\n",
      "<             word_freqs[w] += 1\n",
      "<         else:\n",
      "<             word_freqs[w] = 1\n",
      "---\n",
      ">         word_freqs[w] += 1\n",
      "62,63c59\n",
      "<     # return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
      "<     return word_freq\n",
      "---\n",
      ">     return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.487s\n",
      "user\t0m0.464s\n",
      "sys\t0m0.016s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import defaultdict\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    word_freqs = defaultdict(int)\n",
    "    for w in word_list:\n",
    "        word_freqs[w] += 1\n",
    "    return word_freqs\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
    "        print_all(word_freqs[1:]);\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "John Cassidy suggested using a\n",
    "[Counter](https://docs.python.org/3/library/collections.html#collections.Counter)\n",
    "to further simplify the counting code.\n",
    "This was so successful that\n",
    "frequencies() is now just a thin wrapper around Counter()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3c3\n",
      "< from collections import defaultdict\n",
      "---\n",
      "> from collections import Counter\n",
      "48,51c48\n",
      "<     word_freqs = defaultdict(int)\n",
      "<     for w in word_list:\n",
      "<         word_freqs[w] += 1\n",
      "<     return word_freqs\n",
      "---\n",
      ">     return Counter(word_list)\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.485s\n",
      "user\t0m0.464s\n",
      "sys\t0m0.016s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
    "        print_all(word_freqs[1:]);\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counter objects have a nifty\n",
    "[most_common](https://docs.python.org/3/library/collections.html#collections.Counter.most_common)\n",
    "method\n",
    "which would have made the sorting trivial,\n",
    "but no one spoke up about that at the meeting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Eric Floehr recognized that there was an unnecessary semicolon,\n",
    "so it was removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64c64\n",
      "<         print_all(word_freqs[1:]);\n",
      "---\n",
      ">         print_all(word_freqs[1:])\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.493s\n",
      "user\t0m0.468s\n",
      "sys\t0m0.016s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
    "        print_all(word_freqs[1:])\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do word_freqs[0][0] and word_freqs[0][1] in print_all() mean?\n",
    "They make the function hard to read.\n",
    "Eric Floehr gave them meaningful names to make the code readable.\n",
    "He used tuple unpacking to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63c63,64\n",
      "<         print(word_freqs[0][0], ' - ', word_freqs[0][1])\n",
      "---\n",
      ">         word, frequency = word_freqs[0]\n",
      ">         print(word, ' - ', frequency)\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.486s\n",
      "user\t0m0.440s\n",
      "sys\t0m0.040s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    if(len(word_freqs) > 0):\n",
    "        word, frequency = word_freqs[0]\n",
    "        print(word, ' - ', frequency)\n",
    "        print_all(word_freqs[1:])\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eric Floehr noticed that print_all()\n",
    "was unnecessarily complicated with recursion,\n",
    "so he refactored the function to use a simple for loop.\n",
    "That made the function simple and easy to read. Yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62,63c62\n",
      "<     if(len(word_freqs) > 0):\n",
      "<         word, frequency = word_freqs[0]\n",
      "---\n",
      ">     for word, frequency in word_freqs:\n",
      "65d63\n",
      "<         print_all(word_freqs[1:])\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.487s\n",
      "user\t0m0.460s\n",
      "sys\t0m0.024s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    for word, frequency in word_freqs:\n",
    "        print(word, ' - ', frequency)\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joe Friedrich noticed that the docstring of\n",
    "filter_chars_and_normalize() did not match the\n",
    "behavior of the function,\n",
    "so the docstring was corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20a21\n",
      ">     All letters changed to lowercase.\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.487s\n",
      "user\t0m0.460s\n",
      "sys\t0m0.024s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    All letters changed to lowercase.\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    for word, frequency in word_freqs:\n",
    "        print(word, ' - ', frequency)\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Russ Herrold moved .lower() from\n",
    "filter_chars_and_normalize() to read_file()\n",
    "and was inclined to completely absorb \n",
    "filter_chars_and_normalize() into read_file().\n",
    "\n",
    "It works, but consolidating functionality in fewer functions\n",
    "was not the point of this style,\n",
    "so we did not keep it.\n",
    "(It *is* the point of the\n",
    "[code golf](https://en.wikipedia.org/wiki/Code_golf)\n",
    "style such as in\n",
    "[tf-06.py](https://github.com/crista/exercises-in-programming-style/blob/d521abd5d7aac14af19aa7794aca9ee23c0f8cc5/06-code-golf/tf-06.py).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11c11\n",
      "<     contents of the file as a string\n",
      "---\n",
      ">     lowercase contents of the file as a string\n",
      "14c14\n",
      "<         data = f.read()\n",
      "---\n",
      ">         data = f.read().lower()\n",
      "21d20\n",
      "<     All letters changed to lowercase.\n",
      "24c23\n",
      "<     return pattern.sub(' ', str_data).lower()\n",
      "---\n",
      ">     return pattern.sub(' ', str_data)\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.497s\n",
      "user\t0m0.480s\n",
      "sys\t0m0.012s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    lowercase contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read().lower()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data)\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = f.read().split(',')\n",
    "    # add single-letter words\n",
    "    stop_words.extend(list(string.ascii_lowercase))\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    for word, frequency in word_freqs:\n",
    "        print(word, ' - ', frequency)\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jim Prior changed stop_words from a list to a set.\n",
    "This made searching for words in stop_words fast.\n",
    "Notice that string.ascii_lowercase is directly\n",
    "iterable by the update method.\n",
    "Notice the big reduction in execution time.\n",
    "\n",
    "Review [20160523-cohpy-speed-of-searching-sets-and-lists.ipynb](http://nbviewer.jupyter.org/github/james-prior/cohpy/blob/master/20160523-cohpy-speed-of-searching-sets-and-lists.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11c11\n",
      "<     lowercase contents of the file as a string\n",
      "---\n",
      ">     contents of the file as a string\n",
      "14c14\n",
      "<         data = f.read().lower()\n",
      "---\n",
      ">         data = f.read()\n",
      "20a21\n",
      ">     All letters changed to lowercase.\n",
      "23c24\n",
      "<     return pattern.sub(' ', str_data)\n",
      "---\n",
      ">     return pattern.sub(' ', str_data).lower()\n",
      "38c39\n",
      "<         stop_words = f.read().split(',')\n",
      "---\n",
      ">         stop_words = set(f.read().split(','))\n",
      "40c41\n",
      "<     stop_words.extend(list(string.ascii_lowercase))\n",
      "---\n",
      ">     stop_words.update(string.ascii_lowercase)\n",
      "\n",
      "GOOD: the output is good\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m0.181s\n",
      "user\t0m0.160s\n",
      "sys\t0m0.020s\n"
     ]
    }
   ],
   "source": [
    "%%script diff_python\n",
    "#!/usr/bin/env python3\n",
    "import sys, re, operator, string\n",
    "from collections import Counter\n",
    "\n",
    "#\n",
    "# The functions\n",
    "#\n",
    "def read_file(path_to_file):\n",
    "    \"\"\"\n",
    "    Takes a path to a file and returns the entire\n",
    "    contents of the file as a string\n",
    "    \"\"\"\n",
    "    with open(path_to_file) as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "def filter_chars_and_normalize(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and returns a copy with all nonalphanumeric\n",
    "    chars replaced by white space\n",
    "    All letters changed to lowercase.\n",
    "    \"\"\"\n",
    "    pattern = re.compile('[\\W_]+')\n",
    "    return pattern.sub(' ', str_data).lower()\n",
    "\n",
    "def scan(str_data):\n",
    "    \"\"\"\n",
    "    Takes a string and scans for words, returning\n",
    "    a list of words.\n",
    "    \"\"\"\n",
    "    return str_data.split()\n",
    "\n",
    "def remove_stop_words(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a copy with all stop\n",
    "    words removed\n",
    "    \"\"\"\n",
    "    with open('../stop_words.txt') as f:\n",
    "        stop_words = set(f.read().split(','))\n",
    "    # add single-letter words\n",
    "    stop_words.update(string.ascii_lowercase)\n",
    "    return [w for w in word_list if not w in stop_words]\n",
    "\n",
    "def frequencies(word_list):\n",
    "    \"\"\"\n",
    "    Takes a list of words and returns a dictionary associating\n",
    "    words with frequencies of occurrence\n",
    "    \"\"\"\n",
    "    return Counter(word_list)\n",
    "\n",
    "def sort(word_freq):\n",
    "    \"\"\"\n",
    "    Takes a dictionary of words and their frequencies\n",
    "    and returns a list of pairs where the entries are\n",
    "    sorted by frequency\n",
    "    \"\"\"\n",
    "    return sorted(word_freq.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "def print_all(word_freqs):\n",
    "    \"\"\"\n",
    "    Takes a list of pairs where the entries are sorted by frequency and print them recursively.\n",
    "    \"\"\"\n",
    "    for word, frequency in word_freqs:\n",
    "        print(word, ' - ', frequency)\n",
    "\n",
    "#\n",
    "# The main function\n",
    "#\n",
    "print_all(sort(frequencies(remove_stop_words(scan(filter_chars_and_normalize(read_file(sys.argv[1]))))))[0:25])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "More opportunities:\n",
    "- Name the magic numbers, such as 25.\n",
    "- Give meaningful name to sys.argv[1].\n",
    "- Choose better names.\n",
    "  - Avoid types in names. That often restricts code unnecessarily.\n",
    "- Make better docstrings.\n",
    "- Make PEP-8 compliant.\n",
    "- Delete comments that belabor the obvious.\n",
    "- Use .most_common() method of Counter object (as mentioned earlier).\n",
    "- Compare heapq and collections.Counter.\n",
    "- Write to work in Python 2 and Python 3.\n",
    "- Put top level code in a main() function.\n",
    "  - There is a comment about main function,\n",
    "    but there is no main function, just top level code.\n",
    "- Use generators.\n",
    "  - Could handle very large files that are bigger than memory.\n",
    "---\n",
    "\n",
    "Afterthoughts\n",
    "\n",
    "Focus on readability before speed.\n",
    "\n",
    "Would have been better to focus on one function at a time instead of jumping around.\n",
    "\n",
    "Would have been better to say what the constraints were before starting\n",
    "instead of winging it.\n",
    "- Standard Python (so nothing that needs pip install to use).\n",
    "- Stick to the style. In this case the style was that each function did one thing \\([UNIX philosopy](https://en.wikipedia.org/wiki/The_unix_philosophy)\\) and they were nested.\n",
    "  - The functions are pure functions.\n",
    "    - Their input is only from the arguments.\n",
    "    - The only output is the return value (except print_all()).\n",
    "Maintain the functionality within each function.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
